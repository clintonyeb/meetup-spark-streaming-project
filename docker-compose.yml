version: "3"
services:

  zoo1:
    image: zookeeper:3.4.9
    hostname: zoo1
    container_name: zoo1
    ports:
      - "2181:2181"
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
      ZOO_SERVERS: server.1=zoo1:2888:3888
    volumes:
      - ./zk-single-kafka-single/zoo1/data:/data
      - ./zk-single-kafka-single/zoo1/datalog:/datalog

  kafka1:
    image: confluentinc/cp-kafka:5.5.1
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9092:9092"
      - "9999:9999"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
    volumes:
      - ./zk-single-kafka-single/kafka1/data:/var/lib/kafka/data
    depends_on:
      - zoo1
    links:
      - zoo1

  java-maven:
    image: java-maven
    build:
      context: .
      dockerfile: Dockerfile

  news-collection-service:
    image: java-maven
    volumes:
      - /home/clinton/.m2:/root/.m2
      - $HOME/secrets:/root/secrets
    container_name: news-collection-service
    working_dir: /app
    hostname: news-collection-service
    tty: true
    environment:
      KAFKA_LISTENER: LISTENER_DOCKER_INTERNAL://kafka1:19092
      KAFKA_TOPIC: news-headlines
      KAFKA_CLIENT_ID: 1
      WAIT_HOSTS: zoo1:2181, kafka1:9092
      NEWS_URL: http://api.datanews.io/v1/headlines
      SECRET_FILE: /root/secrets/news-api.secret
      SERVICE_NAME: news-collection-service
      APP_VERSION: 0.0.1
      DEBUG_MODE: "true"
      SAMPLE_FILE: /app/sample-news.json
    restart: on-failure
    depends_on:
      - zoo1
      - kafka1
    links:
      - zoo1
      - kafka1

  sentiment-analysis-service:
    image: java-maven
    volumes:
      - /home/clinton/.m2:/root/.m2
      - $HOME/secrets:/root/secrets
    container_name: sentiment-analysis-service
    working_dir: /app
    hostname: sentiment-analysis-service
    tty: true
    environment:
      KAFKA_LISTENER: LISTENER_DOCKER_INTERNAL://kafka1:19092
      NEWS_KAFKA_TOPIC: news-headlines
      SENTIMENT_KAFKA_TOPIC: sentiment-analysis
      KAFKA_CLIENT_ID: 2
      KAFKA_GROUP_ID: 2
      WAIT_HOSTS: zoo1:2181, kafka1:9092
      SECRET_FILE: /root/secrets/sentiment-api.secret
      SERVICE_NAME: sentiment-analysis-service
      APP_VERSION: 0.0.1
      SENTIMENT_URL: https://twinword-sentiment-analysis.p.rapidapi.com/analyze/
      API_HOST: twinword-sentiment-analysis.p.rapidapi.com
      DEBUG_MODE: "true"
      SAMPLE_FILE: /app/sample-sentiment.json
    restart: on-failure
    depends_on:
      - zoo1
      - kafka1
    links:
      - zoo1
      - kafka1

  spark-master:
    image: bde2020/spark-master:3.1.1-hadoop3.2
    container_name: spark-master
    restart: always
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      INIT_DAEMON_STEP: setup_spark
    depends_on:
      - zoo1
      - kafka1

  spark-worker-1:
    image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker-1
    restart: always
    depends_on:
      - spark-master
      - zoo1
      - kafka1
    ports:
      - "8081:8081"
    environment:
      SPARK_MASTER: spark://spark-master:7077

  hot-topic-analysis-service:
    build:
      context: .
      dockerfile: spark.Dockerfile
    container_name: hot-topic-analysis-service
    hostname: hot-topic-analysis-service
    restart: on-failure
    environment:
      KAFKA_LISTENER: LISTENER_DOCKER_INTERNAL://kafka1:19092
      KAFKA_CLIENT_ID: 3
      KAFKA_GROUP_ID: 3
      SENTIMENT_KAFKA_TOPIC: sentiment-analysis
      SPARK_MASTER_NAME: spark-master
      SPARK_MASTER_PORT: 7077
      SPARK_APPLICATION_MAIN_CLASS: com.clinton.Application
      SPARK_MASTER_URL: spark://spark-master:7077
      ENABLE_INIT_DAEMON: "false"
      HDFS_HOST: hdfs://namenode:9000
      SECRET_FILE: /root/secrets/sentiment-api.secret
      SERVICE_NAME: hot-topic-analysis-service
      APP_VERSION: 0.0.1
      WAIT_HOSTS: spark-master:7077, spark-worker-1:8081, hbase:2182
      DEBUG_MODE: "true"
    depends_on:
      - spark-master
      - spark-worker-1
      - zoo1
      - kafka1
    volumes:
      - /home/clinton/.m2:/root/.m2
      - $HOME/secrets:/root/secrets

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=app-hadoop-cluster
    env_file:
      - ./hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env

  hbase:
    image: bde2020/hbase-standalone:1.0.0-hbase1.2.6
    container_name: hbase
    hostname: app.hbase
    restart: always
    volumes:
      - hbase_data:/hbase-data
      - hbase_zookeeper_data:/zookeeper-data
    ports:
      - "16000:16000"
      - "16010:16010"
      - "16020:16020"
      - "16030:16030"
      - "2888:2888"
      - "3888:3888"
      - "2182:2182"
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hbase-standalone.env

  sentimental-news-api:
    image: java-maven
    volumes:
      - /home/clinton/.m2:/root/.m2
      - $HOME/secrets:/root/secrets
    container_name: sentimental-news-api
    working_dir: /app
    hostname: app.news-api
    tty: true
    ports:
      - "8085:8085"
    environment:
      WAIT_HOSTS: hbase:2182
      SECRET_FILE: /root/secrets/sentiment-api.secret
      SERVICE_NAME: sentimental-news-api
      APP_VERSION: 0.0.1
      DEBUG_MODE: "true"
    restart: on-failure
    depends_on:
      - hbase
    links:
      - hbase

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
  hbase_data:
  hbase_zookeeper_data:
